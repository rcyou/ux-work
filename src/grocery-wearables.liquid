---
layout: layouts/tpl.liquid
seoTitle: Retail Tech Storyboards
metaDescription: Illustrating how sensory-focused tech can help retailers create an inclusive shopping experience for customers of all abilities.
primaryTitle: Grocery Shopping AR Storyboards
ogImagePath: '/images/grocery/og-image-grocery.jpg'
---
<section id="lede" class="page-margin contained">
	<h1>{{ primaryTitle }}</h1>
    <p class="summary big-text-24">{{ metaDescription }}</p>
    <div class="summary-list">
        <span class="small-text-16 mono eyebrow">Role & Activities</span>
        <ul class="bullet-list">
            <li><a href="#user-research">User Research</a></li>
            <li><a href="#illustration">Illustration</a></li>
        </ul>
    </div>
</section>

<section class="page-margin contained">
    <span class="small-text-16 mono eyebrow">Problem</span>
    <h2>How might we provide a more inclusive shopping experience for customers aided by technology?</h2>
    <p>I’ve seen an uptick in people designing Augmented Reality (AR) experiences that show what the future of shopping could be. While fun and thought-provoking, these concepts are primarily optical and overlook the estimated 2.2 billion people worldwide living with a vision impairment.</p>
    <p>When looking at AR as a means of helping sighted users find ingredients or navigate a store, opportunities exist to provide an equal – if not better – experience through technology built for our other senses. The result? Human-centered solutions that work for both disabled and able-bodied customers alike.</p>
    <p>The trouble is, audible and haptic experiences can be difficult to present and, at times, comprehend. Seeing is believeing, after all. Worse yet, working prototypes can be costly to build.</p>
</section>

<figure class="page-margin">
    <video class="small" controls poster="{{ '/images/grocery/ar-concept-screenshot.png' | url }}">
        <source src="{{ '/images/grocery/ar-shopping-reiners.mp4' | url }}" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    <figcaption class="caption small-text-16 mono">AR concept video by Patricia Reiners</figcaption>
</figure>

<section class="page-margin contained">
    <span class="small-text-16 mono eyebrow">Outcome</span>
    <h2 id="user-research">Supermarket superstar</h2>
        <p>Before drawing anything, I did some research to understand the types of people who shop for groceries in the United States. A 2018 market research study by VideoMining suggests men are now just as likely as women to be seen in the asiles – a recent trend supported by other reports from past years.</p>
        <p>Interestingly, research by the Hartman Group found that men tend to have a ‘seek and retreive’ form of shopping, getting in and out of the store as quickly as possible. Survey data from Men’s Health collected around the same time show 66 percent of men also decide what to buy before they get to the store.</p>
        <p>With these details, I created a proto-persona and drafted a scenario to guide the flow for the storyboards.</p>
</section>

<figure class="med page-margin">
    <img class="border" src="{{ '/images/grocery/grocery-persona.jpg' | url }}" loading="lazy" alt="illustrative persona of Shaun, a 40-year-old contractor who is frequently asked to pick up one-off items for his spouse.">
    <figcaption class="caption small-text-16 mono">Persona sketch of Shaun, a 40-year-old contractor who is frequently asked to pick up one-off items for his spouse.</figcaption>
</figure>

<section class="page-margin contained">
    <h2>Hey Siri, Where are the peeled datterini tomatos?</h2>
    <p>Whether it’s a homeowner at the hardware store out to buy a tool for their DIY project, or a spouse sent to the supermarket to purchase a unique ingredient for dinner that night, there is one shopping story as old as time: Searching for something obscure.</p>
    <p>We know Shaun will arrive at the store. And we know he will eventually leave with everything on his list. But what happens in between? I made a rough outline of the journey to answer this. At this point, I wasn’t concerned with shoehorning the story into a set number of frames or panels. I was just concerned with capturing all the actions Shaun would take to get from beginning to end. In a limited sense, this served as my journey map.</p>
</section>

<section class="terminal page-margin">
    <p>- scenario</p>
    <p>Shaun gets a text message from his spouse asking him to pick up some things on his way home. Some items Shaun has never had to buy before. But because most of the the things on the list can be found at the big-box retailer they usually shop at, he assumes everything can be bought there.</p>

    <p>- experience outline</p>
    <ul>
        <li>Arrives at store and checks list</li>
        <li>Not sure what isle an item is in or can’t find the item altogether</li>
        <li>Gets feedback from devices about location</li>
        <li>Navigates to spot in store</li>
        <li>IDs item and puts in cart</li>
        <li>checks out</li>
    </ul>
</section>

<section class="page-margin contained">
    <p>Six panels ended up being working nicely for the layout and the structure also aligned with the 6-stage story format – ideal for making sure we maximize the impact of each panel given the short narrative.</p>
</section>

<figure class="med page-margin contained">
    <img class="multiply" src="{{ '/images/grocery/storyboard-structure.jpg' | url }}" loading="lazy" alt="a six-panel image plotting the user's journey from intro to resolution">
    <figcaption class="caption small-text-16 mono">Plotting Shaun's journey, starting from when he enter's the store and ending at checkout.</figcaption>
</figure>

<section class="page-margin contained">
    <p>From there, I sketched out the scenes, focusing on the Shaun’s mood and the actions he takes to acheive his goal. References to the assisting technology is a mere blip in the story, though its affects account for two-thirds of the journey. This is intentional and meant to represent how a shopper would inject technology into an everyday context rather than depcit the user’s reliance on devices during the entire shopping experience.</p>
</section>

<figure class="med page-margin contained">
    <img class="multiply" src="{{ '/images/grocery/storyboard-panels.jpg' | url }}" loading="lazy" alt="comic panels showing a user checking his shopping list and using his AirPods and Apple Watch to find where something is in a supermarket">
    <figcaption class="caption small-text-16 mono">Shaun checks his shopping list &amp; uses his both his AirPods &amp; Apple Watch to find where something is at the grocery store.</figcaption>
</figure>

<section class="page-margin contained">
    <h2 id="illustration">Domo arigato, Mr. Roboto</h2>
    <p>To better illustrate to stakeholders how haptics, voice technology, and intelligent virtual assistants could be combined help a customer find something in the store, I drew a few additional scenes.</p>
    <p>These demonstrate what the smart watch interface may be like, as well as how users could be guided by a voice interface to learn what has is on their list and where the nearest items would be – all without needing to pull out their phones to look at an app once they walk into the store, potentially blocking entryways or clogging aisle traffic.</p>
</section>

<figure class="med page-margin contained">
    <img src="{{ '/images/grocery/storyboard-haptic.jpg' | url }}" loading="lazy" alt="an illustration showing a woman checking her smart watch to figure out what the next item is she needs to get from her grocery list.">
    <figcaption class="caption small-text-16 mono">How might we help shoppers efficiently move through the store using their grocery lists?</figcaption>
</figure>

<figure class="med page-margin contained">
    <img src="{{ '/images/grocery/storyboard-vui.jpg' | url }}" loading="lazy" alt="an illustration showing a woman using her Apple AirPods to hear her groecery list read aloud, as well as where to find the first items.">
    <figcaption class="caption small-text-16 mono">How might we make shopping for a others feel less overwhelming &amp; facilitate flexible, collaborative grocery planning?</figcaption>
</figure>

<section class="page-margin contained">
    <span class="small-text-16 mono eyebrow">Reflections &amp; Learnings</span>
    <h2>What I liked</h2>
    <p>I enjoyed the story-telling aspect of this project. Adding a narrative to this problem helped me pinpoint the specific points along the journey where someone might lean on audible or heptic information in the physical world. Sometimes, I even assumed the role of an AR contrarian and assumed my user was blind. This got me interested in understanding how people with visual impairments shop.</p>
    <h2>What I learned</h2>
    <p>NFC readers inside our phones and smart watches currently require the device to be right up against a nearby tag in order to detect it. People pressing their wrists against store shelves likely wouldn’t amount to a great experience. Pending user validation, a good first step may be using this technology as a wayfinding method to get someone in the general area of the product they’re looking for.</p>
    <h2>What I lacked</h2>
    <p>One thing I did not account for was how people currently solve this problem when trying to find something in a store, regardless of their physical abilities. My assumption is customers ask an employee. However, the lockdown periods of the Covid-19 pandemic and controversy over indoor face masks has shown us that this may not always be a viable or preferred option.</p>
    <h2>What I longed for</h2>
    <p>While I find it pretty easy to understand the ins and outs of technology, I had a consistent desire to work with a development team to identify how much further this project could go. Especially when it comes to the intersection of hardware and software, I find it valuable to have a technical collaborator to share in the ideation and experimentation phases.</p>
</section>